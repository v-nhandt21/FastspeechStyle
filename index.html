<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>FastspeechStyle</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="css/normalize.css">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="css/cayman.css">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">FastSpeechStyle: Fast, Emotion Controllable and  <br> High-Quality Speech Synthesis</h1>
      <h2 class="project-tagline">Van Thinh Nguyen, Tri-Nhan Do, Hung-Cuong Pham, Tuan Vu Ho, Dang-Khoa Mac <br> VinBigData Joint Stock Company</h2>
      <!-- <h2 class="project-tagline">Email: tuanvu.ho@jaist.ac.jp <br> LinkedIn: <a href="https://www.linkedin.com/in/tuanvuho/" style="color:white">https://www.linkedin.com/in/tuanvuho/</a></h2>
      <a href="https://github.com/tuanvu92/VCC2020" class="btn">Code</a>
      <a href="https://www.isca-speech.org/archive/VCC_BC_2020/pdfs/VCC2020_paper_21.pdf" class="btn">Paper</a>
      <a href="https://youtu.be/-0unANTbbro" class="btn">Presentation Video</a> -->
    </section>

    <section class="main-content">
      <h1>
      <a id="user-content-header-1" class="anchor" href="#header-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Abstract</h1>

      <p>The Non-autoregressive text to speech models such as Fastspeech2 can fast synthesize the high quality speech. This model also allows explicit control of the pitch, energy and speed of the speech signal. But, to control the emotion while maintaining the natural human-like speech is still a problems. In this paper, we propose an expressive speech synthesis model that can synthesize high-quality speech with desired emotion. The proposed model includes two main components (1) Mel Emotion Encoder extracts emotion embedding from the Mel-spectrogram of audio, (2) the FastSpeechStyle, a non-autoregressive model, which is modified from vanilla Fastspeech2. The FastSpeechStyle replaces normal LayerNorm with Style Adaptive LayerNorm to "shift" and "scale" hidden features according to emotion embedding, the model also used an improved Conformer block instead of vanilla FFTBlock to better model the local and global dependency in the acoustic model.</p>
      <figure>
        <img src="html/img/Architecture.png" alt="" style="max-width:80%;margin-left:auto; margin-right:auto;display:block;" >
        <figcaption style="max-width:80%;margin-left:auto; margin-right:auto;display:block;">Emotional Speech Synthesis Architecture. Figure (a) shows the overall pipeline for FastSpeechStyle. Figure (b) shows the improved Conformer block and the integration of emotional embedding through Adaptive Layer Norm.</figcaption>
      </figure>
      <br>
      <figure>
        <img src="html/img/clustering.png" alt="" style="max-width:100%;margin-left:auto; margin-right:auto;display:block;" >
        <figcaption style="max-width:80%;margin-left:auto; margin-right:auto;display:block;">T-SNE visualization of emotional embeddings of typical samples.</figcaption>
      </figure>
      <br>
      <figure>
        <img src="html/img/table1.png" alt="" style="max-width:100%;margin-left:auto; margin-right:auto;display:block;" >
        <figcaption style="max-width:80%;margin-left:auto; margin-right:auto;display:block;">.</figcaption>
      </figure>
      <br>
      <figure>
        <img src="html/img/table2.png" alt="" style="max-width:100%;margin-left:auto; margin-right:auto;display:block;" >
        <figcaption style="max-width:80%;margin-left:auto; margin-right:auto;display:block;">.</figcaption>
      </figure>

      <hr>
      <h1>
      <a id="user-content-header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Samples</h1>
      <!-- <h2>Task 1: Intra-lingual Voice Conversion</h2> -->
      
      <h3>Sample 1: <audio controls><source src="html/audio/groundtruth/008653.wav" type="audio/wav"></audio></h3>
      <p>chứ anh bán sách ở đây tui trả lương cho anh anh không phải là nhân viên của tui anh là cái gì</p>
      
      <table>
        <tr>
          <td></td>
          <td>Baseline</td>
          <td>Proposed</td>
        </tr>
        <tr>
          <td>Sad</td>
          <td><audio controls><source src="html/audio/fastspeech2style_fft_sad/008653.wav" type="audio/wav"></audio></td>
          <td><audio controls><source src="html/audio/fastspeech2style_conformer_sad/008653.wav" type="audio/wav"></audio></td>
        </tr>
        <tr>
          <td>Happy</td>
          <td><audio controls><source src="html/audio/fastspeech2style_fft_happy/008653.wav" type="audio/wav"></audio></td>
          <td><audio controls><source src="html/audio/fastspeech2style_conformer_happy/008653.wav" type="audio/wav"></audio></td>
        </tr>
        <tr>
          <td>Neutral</td>
          <td><audio controls><source src="html/audio/fastspeech2style_fft_neutral/008653.wav" type="audio/wav"></audio></td>
          <td><audio controls><source src="html/audio/fastspeech2style_conformer_neutral/008653.wav" type="audio/wav"></audio></td>
        </tr>
        <tr>
          <td>Angry</td>
          <td><audio controls><source src="html/audio/fastspeech2style_fft_angry/008653.wav" type="audio/wav"></audio></td>
          <td><audio controls><source src="html/audio/fastspeech2style_conformer_angry/008653.wav" type="audio/wav"></audio></td>
        </tr>
      </table>

      <!-- <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/tuanvu92/VCC2020">VCC2020 Demo</a> is maintained by <a href="https://github.com/tuanvu92">tuanvu92</a>.</span>
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer> -->
    </section>

  </body>
</html>
